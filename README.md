ğŸ™ï¸ Cross-Lingual Speech Emotion Recognition (SER) System
ğŸš€ Overview

This project is an AI-powered Speech Emotion Recognition (SER) system capable of identifying human emotions such as Angry, Happy, Neutral, and Sad from raw audio.
It supports cross-lingual emotion classification using two benchmark datasets:
RAVDESS (English)
Emo-DB (German)

The project includes a full pipeline from preprocessing â†’ training â†’ evaluation â†’ real-time inference UI (Gradio).
Designed for emotion-aware AI, call centers, healthcare monitoring, virtual assistants, and mental health analysis.

ğŸ¯ Features:
âœ… Cross-Lingual Emotion Recognition â€“ Works on English + German
ğŸ¤ Raw Audio Input â€“ No MFCCs required
ğŸ§  Transformer-Based Model â€“ Wav2Vec2 (Facebook AI)
âš¡ High Accuracy (~90%) â€“ On combined test set
ğŸ“š Automatic Metadata Generation
ğŸ§¹ Advanced Preprocessing â€“ Resampling, trimming, normalization
ğŸ“Š Test Results â€“ Includes per-language performance
ğŸ›ï¸ Real-Time Emotion Detector â€“ Microphone + File input
ğŸŒ Gradio-Based UI for deployment

ğŸ—ï¸ Tech Stack:
ğŸ”¹ Python â€“ Core programming
ğŸ”¹ PyTorch â€“ Deep learning framework
ğŸ”¹ HuggingFace Transformers â€“ Wav2Vec2 model
ğŸ”¹ Librosa / SoundFile â€“ Audio loading + processing
ğŸ”¹ Scikit-learn â€“ Metrics + train/test split
ğŸ”¹ Gradio â€“ Real-time inference interface

ğŸ“¦ Installation

Clone the repository and install dependencies:

git clone https://github.com/gazalyadav/Cross-Lingual-SER-Project.git
cd Cross-Lingual-SER-Project
pip install -r requirements.txt

â–¶ï¸ Running the Project
1ï¸âƒ£ Preprocess the datasets

This step loads RAVDESS + Emo-DB, resamples audio to 16kHz, normalizes it, and creates metadata.

python src/preprocess.py

Output is stored in:

data/processed/
    â”œâ”€â”€ *.wav
    â””â”€â”€ metadata.json

2ï¸âƒ£ Train the Wav2Vec2 SER Model
python src/train.py

Expected Results
Dataset	Accuracy	Weighted F1
English	~91%	~0.91
German	~87%	~0.87
Combined	~89â€“90%	~0.90

3ï¸âƒ£ Run the Real-Time Gradio App
python src/app_gradio.py


App starts at:
ğŸ”— http://127.0.0.1:7860

You can:
ğŸ¤ Speak using Microphone
ğŸ“ Upload a .wav file
ğŸ“Š View predicted emotion instantly


ğŸ“‘ File Structure
CrossLingual_SER/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ RAVDESS/
â”‚   â”‚   â””â”€â”€ EMODB/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ *.wav
â”‚       â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ wav2vec2_base_crosslingual_ser.pt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ app_gradio.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ â€¦
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ† How It Works
1. Start Preprocessing
Loads RAVDESS + Emo-DB â†’ Converts to mono â†’ Resamples to 16 kHz â†’ Normalizes â†’ Saves processed files.

2. Train the SER Model
Wav2Vec2 extracts features directly from raw waveforms â†’ Softmax classifier predicts emotions.

3. Test the Model
Calculates Accuracy + F1 + per-language performance (English/German).

4. Real-Time Prediction
You speak â†’ Audio processed â†’ Wav2Vec2 inference â†’ Emotion displayed instantly.

ğŸš€ Future Enhancements

ğŸ“Œ Add Hindi + Multilingual Indian datasets
ğŸ“Œ Add gender + speaker ID
ğŸ“Œ Deploy on HuggingFace Spaces
ğŸ“Œ Convert to ONNX for mobile deployment
ğŸ“Œ Add live streaming via WebSockets

ğŸ¤ Contributing
Contributions are welcome!
Fork â†’ Create a branch â†’ Commit â†’ Open PR.

ğŸ”— License
MIT License â€“ Free to use and modify.

ğŸ“ Author
Gazall Yadav
AI/ML Developer | SER Researcher
ğŸ”— GitHub: https://github.com/gazalyadav




