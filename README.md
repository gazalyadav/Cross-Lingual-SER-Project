ğŸ™ï¸ Cross-Lingual Speech Emotion Recognition (SER) Using Wav2Vec2
ğŸš€ Overview

This project is an AI-powered emotion recognition system that analyzes human speech and predicts emotional states such as Angry, Happy, Neutral, and Sad.
It is built using state-of-the-art Transformer-based models (Wav2Vec2) and supports cross-lingual emotion recognition across English (RAVDESS) and German (Emo-DB) speech.

The system includes a complete pipeline:
ğŸ“¥ Data preprocessing â†’ ğŸ§  Model training â†’ ğŸ§ Real-time inference â†’ ğŸŒ Deployment.

It is designed for applications such as call centers, healthcare monitoring, virtual assistants, mental health analysis, and emotionally aware AI systems.

ğŸ¯ Features

âœ… Cross-Lingual Emotion Recognition â€“ Works across English + German datasets
ğŸ¤ Raw Audio Input â€“ No MFCCs required
ğŸ§  Transformer-based Model â€“ Uses Wav2Vec2 (Facebook AI)
âš¡ High Accuracy â€“ ~90% accuracy on combined test set
ğŸ“ˆ Balanced Label Mapping â€“ Unified emotion labels across datasets
ğŸ”Š Real-Time Emotion Detection App â€“ Built using Gradio
ğŸ“‚ Metadata & Processed Audio Generation
ğŸ›  Robust Preprocessing Pipeline â€“ Resampling, trimming, normalization

ğŸ—ï¸ Tech Stack

ğŸ”¹ Python
ğŸ”¹ PyTorch
ğŸ”¹ HuggingFace Transformers
ğŸ”¹ Torchaudio / Librosa
ğŸ”¹ Scikit-learn
ğŸ”¹ Gradio (Real-time inference UI)

ğŸ“¦ Installation
Clone the repository
git clone https://github.com/gazalyadav/Cross-Lingual-SER-Project.git
cd Cross-Lingual-SER-Project

Create Conda environment
conda create -n ser python=3.10
conda activate ser

Install dependencies
pip install -r requirements.txt

â–¶ï¸ Running the Project
1ï¸âƒ£ Preprocess the datasets

This step loads RAVDESS + Emo-DB, resamples audio, normalizes, and generates metadata.

python src/preprocess.py


It creates:

data/processed/
     â”œâ”€â”€ *.wav
     â””â”€â”€ metadata.json

2ï¸âƒ£ Train the SER Model
python src/train.py


Expected output:

Dataset	Accuracy	Weighted F1
English	~91%	~0.91
German	~87%	~0.87
Combined	~89â€“90%	~0.90
3ï¸âƒ£ Run the Real-Time App
python src/app_gradio.py


You can now use:

ğŸ¤ Microphone recording
ğŸ”Š WAV file upload
ğŸ“Š Instant emotion prediction

Runs locally at:

http://127.0.0.1:7860

ğŸ“¸ Screenshots (Add Yours)

You may add screenshots like this:

or upload snapshots of your Gradio UI / terminal output / project structure.

ğŸ“‘ File Structure
CrossLingual_SER/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ RAVDESS/
â”‚   â”‚   â””â”€â”€ EMODB/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ *.wav
â”‚       â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ wav2vec2_base_crosslingual_ser.pt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ app_gradio.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ â€¦
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ§  How It Works (Pipeline)

Data Input
Loads emotional speech from RAVDESS & Emo-DB.

Preprocessing
âœ” Resampling to 16 kHz
âœ” Mono conversion
âœ” Trimming
âœ” Normalization
âœ” Label harmonization

Feature Extraction
Transformer extracts contextual features from raw waveforms.

Training

Wav2Vec2-base model

AdamW optimizer

Balanced class weights

10 epochs

Prediction
Real-time microphone or audio upload â†’ Wav2Vec2 â†’ Emotion output.

Deployment
Gradio app for instant demo.

ğŸš€ Future Enhancements

ğŸ“Œ Hindi + Multi-Indian-language Dataset Support
ğŸ“Œ Add Gender Detection + Emotion Fusion
ğŸ“Œ Convert model to ONNX for mobile apps
ğŸ“Œ Deploy on HuggingFace Spaces
ğŸ“Œ Add real-time streaming (WebSocket)

ğŸ¤ Contributing

Contributions are welcome!
You can fork the project, create a branch, and submit a pull request.

ğŸ”— License

MIT License â€” free to use and modify.

ğŸ“ Author

Gazall Yadav
AI/ML Developer | SER Researcher | Emotion-Aware Systems
GitHub: https://github.com/gazalyadav
